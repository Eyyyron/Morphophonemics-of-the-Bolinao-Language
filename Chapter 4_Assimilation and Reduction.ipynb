{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4555366"
   },
   "source": [
    "## Undoing Assimilation and Reduction in the Bolinao Lexicon\n",
    "\n",
    "A process of assimilation and reduction occurs when prefixes ending in /ng/ (maNg-, naNg-, paNg-) attach to a word beginning with a stop or s (p, b, t, d, s, ', k, g). The /ng/ assimilates to the point of articulation and the initial consonant of the word is removed. Otherwise (words beginning with y, w, l, r, m, n, ng), the Ng remains as /ng/ and reduction does not take place. The tendency of ng to assimilate in this manner can also be found interword such as in compounding.\n",
    "\n",
    "\n",
    "Rules:\n",
    "*   maNg- + /p/ → ma- + m + reduced word\n",
    "*   maNg- + /b/ → ma- + m + reduced word\n",
    "*   naNg- + /p/ → na- + m + reduced word\n",
    "*   naNg- + /b/ → na- + m + reduced word\n",
    "*   paNg- + /p/ → pa- + m + reduced word\n",
    "*   paNg- + /b/ → pa- + m + reduced word\n",
    "------------------------------------------------\n",
    "*   maNg- + /d/ → ma- + n + reduced word\n",
    "*   maNg- + /t/ → ma- + n + reduced word\n",
    "*   maNg- + /s/ → ma- + n + reduced word\n",
    "*   naNg- + /d/ → na- + n + reduced word\n",
    "*   naNg- + /t/ → na- + n + reduced word\n",
    "*   naNg- + /s/ → na- + n + reduced word\n",
    "*   paNg- + /d/ → pa- + n + reduced word\n",
    "*   paNg- + /t/ → pa- + n + reduced word\n",
    "*   paNg- + /s/ → pa- + n + reduced word\n",
    "------------------------------------------------\n",
    "*   maNg- + /k/ → ma- + ng + reduced word\n",
    "*   maNg- + /g/ → ma- + ng + reduced word\n",
    "*   maNg- + /'/ → ma- + ng + reduced word\n",
    "*   naNg- + /k/ → na- + ng + reduced word\n",
    "*   naNg- + /g/ → na- + ng + reduced word\n",
    "*   naNg- + /'/ → na- + ng + reduced word\n",
    "*   paNg- + /k/ → pa- + ng + reduced word\n",
    "*   paNg- + /g/ → pa- + ng + reduced word\n",
    "*   paNg- + /'/ → pa- + ng + reduced word\n",
    "------------------------------------------------\n",
    "*   maNg- + /not k, g, '/ → ma- + ng + unreduced word\n",
    "*   naNg- + /not k, g, '/ → ma- + ng + unreduced word\n",
    "*   paNg- + /not k, g, '/ → ma- + ng + unreduced word\n",
    "\n",
    "Examples:\n",
    "* mang + basa → mamasa “to read”\n",
    "* mang + pa + ta’gay → mamata’gay “to go up”\n",
    "* mang + saliw → manaliw “to buy”\n",
    "* mang + kalap → mangalap “to get, remove”\n",
    "* mang + aluyon → mangaluyon “to accompany”\n",
    "* mang + lipot → manglipot “to give over”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31196f12"
   },
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "This step loads the Excel-like file containing Bolinao words and prepares tools for text processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hairdfhIsKlm"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "ii2K0MqaGeFc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"Bolinao Lexicon Final.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54g9CAHYGo0J"
   },
   "source": [
    "Filter only those starting with assimilation prefixes.\n",
    "\n",
    "Words that starts with \"mam\", \"man\", \"mang\", \"nam\", \"nan\",  \"nang\", \"pam\", \"pan\", and \"pang\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b500a943"
   },
   "source": [
    "## 2. Filter Words with Assimilation Prefixes\n",
    "\n",
    "This step filters the dataset to include only those words starting with the assimilation prefixes: \"mam\", \"man\", \"mang\", \"nam\", \"nan\", \"nang\", \"pam\", \"pan\", and \"pang\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "XqH0TXSyGpCS"
   },
   "outputs": [],
   "source": [
    "candidates = df[df[\"word\"].str.startswith((\"mam\", \"man\", \"mang\", \"nam\", \"nan\",  \"nang\", \"pam\", \"pan\", \"pang\"), na=False)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "576d5c9a"
   },
   "source": [
    "## 3. Define Root Word Recovery Function\n",
    "\n",
    "This function is designed to reverse the sound changes caused by assimilation and reduction, aiming to find the original root word before prefixes were added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "zqNJd6tPGpSV"
   },
   "outputs": [],
   "source": [
    "# Define assimilation + reduction rules\n",
    "def undo_assimilation_reduction(word):\n",
    "    original = word\n",
    "    process = []\n",
    "    formula = []\n",
    "    root = word  # default if no change\n",
    "\n",
    "    if word.startswith(\"mang\"):\n",
    "        rest = word[4:]\n",
    "        if rest and rest[0] in [\"y\", \"w\", \"l\", \"r\", \"m\", \"n\"]:  # y/w/l/r/m/n root\n",
    "            root = rest\n",
    "            process.append(\"no reduction\")\n",
    "            formula.append(\"mang- with root starting y/w/l/r/m/n/ng (ng stays)\")\n",
    "        else:  # k, g, ' root\n",
    "            root = \"k\" + rest + \"|\" + \"g\" + rest + \"|\" + \"'\" + rest + \"|\" + rest\n",
    "            process.append(\"assimilation+reduction|no reduction for a/e/i/o/u\")\n",
    "            formula.append(\"mang- + (k/g/' root (consonant dropped, ng kept)|mang- with root starting a/e/i/o/u (ng stays))\")\n",
    "\n",
    "    elif word.startswith(\"mam\"):  # mang- + p/b root\n",
    "        root = \"b\" + word[3:] + \"|\" + \"p\" + word[3:]\n",
    "        process.append(\"assimilation+reduction\")\n",
    "        formula.append(\"mam- from mang- + p/b root (p/b dropped, ng→m)\")\n",
    "\n",
    "    elif word.startswith(\"man\"):  # mang- + t/d/s root\n",
    "        root = \"s\" + word[3:] + \"|\" + \"t\" + word[3:] + \"|\" + \"d\" + word[3:]\n",
    "        process.append(\"assimilation+reduction\")\n",
    "        formula.append(\"man- from mang- + t/d/s root (consonant dropped, ng→n)\")\n",
    "\n",
    "    elif word.startswith(\"nang\"):\n",
    "        rest = word[4:]\n",
    "        if rest and rest[0] in [\"y\", \"w\", \"l\", \"r\", \"m\", \"n\"]:  # y/w/l/r/m/n root\n",
    "            root = rest\n",
    "            process.append(\"no reduction\")\n",
    "            formula.append(\"nang- with root starting y/w/l/r/m/n/ng (ng stays)\")\n",
    "        else:  # k, g, ' root\n",
    "            root = \"k\" + rest + \"|\" + \"g\" + rest + \"|\" + \"'\" + rest + \"|\" + rest\n",
    "            process.append(\"assimilation+reduction|no reduction for a/e/i/o/u\")\n",
    "            formula.append(\"nang- + (k/g/' root (consonant dropped, ng kept)|nang- with root starting a/e/i/o/u (ng stays))\")\n",
    "\n",
    "    elif word.startswith(\"nam\"):  # nang- + p/b root\n",
    "        root = \"b\" + word[3:] + \"|\" + \"p\" + word[3:]\n",
    "        process.append(\"assimilation+reduction\")\n",
    "        formula.append(\"nam- from nang- + p/b root (p/b dropped, ng→m)\")\n",
    "\n",
    "    elif word.startswith(\"nan\"):  # nang- + t/d/s root\n",
    "        root = \"s\" + word[3:] + \"|\" + \"t\" + word[3:] + \"|\" + \"d\" + word[3:]\n",
    "        process.append(\"assimilation+reduction\")\n",
    "        formula.append(\"nan- from nang- + t/d/s root (consonant dropped, ng→n)\")\n",
    "\n",
    "    elif word.startswith(\"pang\"):\n",
    "        rest = word[4:]\n",
    "        if rest and rest[0] in [\"y\", \"w\", \"l\", \"r\", \"m\", \"n\"]:  # y/w/l/r/m/n root\n",
    "            root = rest\n",
    "            process.append(\"no reduction\")\n",
    "            formula.append(\"pang- with root starting y/w/l/r/m/n/ng (ng stays)\")\n",
    "        else:  # k, g, ' root\n",
    "            root = \"k\" + rest + \"|\" + \"g\" + rest + \"|\" + \"'\" + rest + \"|\" + rest\n",
    "            process.append(\"assimilation+reduction|no reduction for a/e/i/o/u\")\n",
    "            formula.append(\"pang- + (k/g/' root (consonant dropped, ng kept)|pang- with root starting a/e/i/o/u (ng stays))\")\n",
    "\n",
    "    elif word.startswith(\"pam\"):  # pang- + p/b root\n",
    "        root = \"b\" + word[3:] + \" |\" + \"p\" + word[3:]\n",
    "        process.append(\"assimilation+reduction\")\n",
    "        formula.append(\"pam- from pang- + p/b root (p/b dropped, ng→m)\")\n",
    "\n",
    "    elif word.startswith(\"pan\"):  # pang- + t/d/s root\n",
    "        root = \"s\" + word[3:] + \"|\" + \"t\" + word[3:] + \"|\" + \"d\" + word[3:]\n",
    "        process.append(\"assimilation+reduction\")\n",
    "        formula.append(\"pan- from pang- + t/d/s root (consonant dropped, ng→n)\")\n",
    "\n",
    "    else:\n",
    "        process.append(\"unchanged\")\n",
    "        formula.append(\"does not match assimilation/reduction patterns\")\n",
    "\n",
    "    return pd.Series({\n",
    "        \"word\": original,\n",
    "        \"root_word\": root,\n",
    "        \"process\": \", \".join(process),\n",
    "        \"formula\": \"; \".join(formula)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daf8a08f"
   },
   "source": [
    "## 4. Apply Root Word Recovery\n",
    "\n",
    "This step applies the `undo_assimilation_reduction` function to each word identified in Step 3 to generate potential root word candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "iciJjubtGpgO"
   },
   "outputs": [],
   "source": [
    "results_df = candidates[\"word\"].dropna().apply(undo_assimilation_reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d37a209"
   },
   "source": [
    "## 5. Combine Original Data with Analysis\n",
    "\n",
    "This step merges the original word data (including meaning and part of speech) with the results of the root word analysis. The resulting data includes the columns: \"word\", \"upos\", \"meaning_english\", \"root_word\", \"process\", and \"formula\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "HIsm7qyyGpvt"
   },
   "outputs": [],
   "source": [
    "results_full = candidates[[\"word\", \"upos\", \"meaning_english\"]].merge(\n",
    "    results_df, left_on=\"word\", right_on=\"word\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "852b0f8b"
   },
   "source": [
    "## 6. Verify Root Word Candidates\n",
    "\n",
    "This step checks if the predicted root words generated in Step 5 actually exist in the original dictionary and whether their meanings align with the assimilated/reduced words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "IMzT3f5lGp-9"
   },
   "outputs": [],
   "source": [
    "confirmed = []\n",
    "\n",
    "for idx, row in results_full.iterrows():\n",
    "    word = row['word']\n",
    "    meaning = row['meaning_english']\n",
    "    upos_assimilated_reduced = row['upos']\n",
    "    roots = row['root_word'].split('|')  # Split multiple root candidates\n",
    "\n",
    "    for r in roots:\n",
    "        r = r.strip()  # Remove extra spaces\n",
    "        # Look for exact matches in the lexicon\n",
    "        match = df[df['word'].str.strip() == r.strip()]\n",
    "        if not match.empty:\n",
    "            record = {\n",
    "                \"assimilated\": word,\n",
    "                \"root_candidate\": r,\n",
    "                \"meaning_assimilated_reduced\": meaning,\n",
    "                \"meaning_root\": \"; \".join(match['meaning_english'].unique()),\n",
    "                \"upos_assimilated_reduced\": upos_assimilated_reduced,\n",
    "                \"upos_root\": \"; \".join(match['upos'].unique()) if 'upos' in match.columns else \"; \".join(match['part_of_speech'].unique())\n",
    "            }\n",
    "            confirmed.append(record)\n",
    "\n",
    "confirmed_df = pd.DataFrame(confirmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4e8fe01"
   },
   "source": [
    "## 7. Export Results\n",
    "\n",
    "This step saves the confirmed root words and their corresponding information to a CSV file for further analysis or use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "2DzWjWlnE00M"
   },
   "outputs": [],
   "source": [
    "confirmed_df.to_csv(\"bolinao_root_words_assimilation_and_reduction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Redo Process: Apply Assimilation and Reduction\n",
    "\n",
    "This step performs the forward process - applying assimilation and reduction rules to root words to verify that we can reconstruct the original assimilated/reduced forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_assimilation_reduction(prefix, root):\n",
    "    \"\"\"\n",
    "    Apply assimilation and reduction rules to reconstruct the assimilated form.\n",
    "    \n",
    "    prefix: one of \"mang\", \"nang\", \"pang\"\n",
    "    root: the root word\n",
    "    \n",
    "    Returns the assimilated/reduced form\n",
    "    \"\"\"\n",
    "    if not root:\n",
    "        return prefix\n",
    "    \n",
    "    first_char = root[0].lower()\n",
    "    \n",
    "    # Rule 1: prefix + p/b roots → assimilated form with 'm'\n",
    "    if first_char in ['p', 'b']:\n",
    "        # Remove 'ng' from prefix and add 'm', then drop first consonant of root\n",
    "        base = prefix[:-2]  # ma, na, or pa\n",
    "        return base + 'm' + root[1:]\n",
    "    \n",
    "    # Rule 2: prefix + t/d/s roots → assimilated form with 'n'\n",
    "    elif first_char in ['t', 'd', 's']:\n",
    "        # Remove 'ng' from prefix and add 'n', then drop first consonant of root\n",
    "        base = prefix[:-2]  # ma, na, or pa\n",
    "        return base + 'n' + root[1:]\n",
    "    \n",
    "    # Rule 3: prefix + k/g/' roots → keep 'ng', drop first consonant of root\n",
    "    elif first_char in ['k', 'g', \"'\"]:\n",
    "        # Keep the full prefix (mang, nang, pang) and drop first consonant\n",
    "        return prefix + root[1:]\n",
    "    \n",
    "    # Rule 4: prefix + y/w/l/r/m/n/ng or vowels → keep 'ng', no reduction\n",
    "    elif first_char in ['y', 'w', 'l', 'r', 'm', 'n'] or first_char in ['a', 'e', 'i', 'o', 'u']:\n",
    "        # Keep the full prefix and full root\n",
    "        return prefix + root\n",
    "    \n",
    "    else:\n",
    "        # Default: no change\n",
    "        return prefix + root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate All Possible Assimilated Forms from Root Words\n",
    "\n",
    "This step truly starts from root words and generates ALL 3 possible assimilated forms (mang-, nang-, pang-) for each confirmed root, without looking at the original assimilated word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique roots: 87\n",
      "Total generated forms: 261 (3 per root)\n",
      "Forms that exist in lexicon: 9\n",
      "\n",
      "First 30 generated forms:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_word</th>\n",
       "      <th>root_meaning</th>\n",
       "      <th>prefix_applied</th>\n",
       "      <th>generated_form</th>\n",
       "      <th>exists_in_lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gamet</td>\n",
       "      <td>hand</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangamet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gamet</td>\n",
       "      <td>hand</td>\n",
       "      <td>nang</td>\n",
       "      <td>nangamet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gamet</td>\n",
       "      <td>hand</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangamet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wiri</td>\n",
       "      <td>left</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangwiri</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wiri</td>\n",
       "      <td>left</td>\n",
       "      <td>nang</td>\n",
       "      <td>nangwiri</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wiri</td>\n",
       "      <td>left</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangwiri</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wanan</td>\n",
       "      <td>right</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangwanan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wanan</td>\n",
       "      <td>right</td>\n",
       "      <td>nang</td>\n",
       "      <td>nangwanan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wanan</td>\n",
       "      <td>right</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangwanan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bitih</td>\n",
       "      <td>leg/foot</td>\n",
       "      <td>mang</td>\n",
       "      <td>mamitih</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bitih</td>\n",
       "      <td>leg/foot</td>\n",
       "      <td>nang</td>\n",
       "      <td>namitih</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bitih</td>\n",
       "      <td>leg/foot</td>\n",
       "      <td>pang</td>\n",
       "      <td>pamitih</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>daan</td>\n",
       "      <td>road/path</td>\n",
       "      <td>mang</td>\n",
       "      <td>manaan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>daan</td>\n",
       "      <td>road/path</td>\n",
       "      <td>nang</td>\n",
       "      <td>nanaan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>daan</td>\n",
       "      <td>road/path</td>\n",
       "      <td>pang</td>\n",
       "      <td>panaan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tangoy</td>\n",
       "      <td>to swim</td>\n",
       "      <td>mang</td>\n",
       "      <td>manangoy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tangoy</td>\n",
       "      <td>to swim</td>\n",
       "      <td>nang</td>\n",
       "      <td>nanangoy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tangoy</td>\n",
       "      <td>to swim</td>\n",
       "      <td>pang</td>\n",
       "      <td>panangoy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tapok</td>\n",
       "      <td>dust</td>\n",
       "      <td>mang</td>\n",
       "      <td>manapok</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tapok</td>\n",
       "      <td>dust</td>\n",
       "      <td>nang</td>\n",
       "      <td>nanapok</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tapok</td>\n",
       "      <td>dust</td>\n",
       "      <td>pang</td>\n",
       "      <td>panapok</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>katat</td>\n",
       "      <td>skin</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangatat</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>katat</td>\n",
       "      <td>skin</td>\n",
       "      <td>nang</td>\n",
       "      <td>nangatat</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>katat</td>\n",
       "      <td>skin</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangatat</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gorot</td>\n",
       "      <td>back</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangorot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gorot</td>\n",
       "      <td>back</td>\n",
       "      <td>nang</td>\n",
       "      <td>nangorot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gorot</td>\n",
       "      <td>back</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangorot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tyan</td>\n",
       "      <td>belly</td>\n",
       "      <td>mang</td>\n",
       "      <td>manyan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tyan</td>\n",
       "      <td>belly</td>\n",
       "      <td>nang</td>\n",
       "      <td>nanyan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tyan</td>\n",
       "      <td>belly</td>\n",
       "      <td>pang</td>\n",
       "      <td>panyan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   root_word root_meaning prefix_applied generated_form  exists_in_lexicon\n",
       "0      gamet         hand           mang       mangamet              False\n",
       "1      gamet         hand           nang       nangamet              False\n",
       "2      gamet         hand           pang       pangamet              False\n",
       "3       wiri         left           mang       mangwiri              False\n",
       "4       wiri         left           nang       nangwiri              False\n",
       "5       wiri         left           pang       pangwiri              False\n",
       "6      wanan        right           mang      mangwanan              False\n",
       "7      wanan        right           nang      nangwanan              False\n",
       "8      wanan        right           pang      pangwanan              False\n",
       "9      bitih     leg/foot           mang        mamitih              False\n",
       "10     bitih     leg/foot           nang        namitih              False\n",
       "11     bitih     leg/foot           pang        pamitih              False\n",
       "12      daan    road/path           mang         manaan              False\n",
       "13      daan    road/path           nang         nanaan              False\n",
       "14      daan    road/path           pang         panaan              False\n",
       "15    tangoy      to swim           mang       manangoy              False\n",
       "16    tangoy      to swim           nang       nanangoy              False\n",
       "17    tangoy      to swim           pang       panangoy              False\n",
       "18     tapok         dust           mang        manapok              False\n",
       "19     tapok         dust           nang        nanapok              False\n",
       "20     tapok         dust           pang        panapok              False\n",
       "21     katat         skin           mang       mangatat              False\n",
       "22     katat         skin           nang       nangatat              False\n",
       "23     katat         skin           pang       pangatat              False\n",
       "24     gorot         back           mang       mangorot              False\n",
       "25     gorot         back           nang       nangorot              False\n",
       "26     gorot         back           pang       pangorot              False\n",
       "27      tyan        belly           mang         manyan              False\n",
       "28      tyan        belly           nang         nanyan              False\n",
       "29      tyan        belly           pang         panyan              False"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# WORD LIST - Place your root words here\n",
    "# ============================================\n",
    "root_word_list = [\n",
    "    {\"root\": \"gamet\", \"meaning\": \"hand\"}, {\"root\": \"wiri\", \"meaning\": \"left\"},\n",
    "    {\"root\": \"wanan\", \"meaning\": \"right\"}, {\"root\": \"bitih\", \"meaning\": \"leg/foot\"},\n",
    "    {\"root\": \"daan\", \"meaning\": \"road/path\"}, {\"root\": \"tangoy\", \"meaning\": \"to swim\"},\n",
    "    {\"root\": \"tapok\", \"meaning\": \"dust\"}, {\"root\": \"katat\", \"meaning\": \"skin\"},\n",
    "    {\"root\": \"gorot\", \"meaning\": \"back\"}, {\"root\": \"tyan\", \"meaning\": \"belly\"},\n",
    "    {\"root\": \"botol\", \"meaning\": \"bone\"}, {\"root\": \"agtay\", \"meaning\": \"liver\"},\n",
    "    {\"root\": \"soso\", \"meaning\": \"breast\"}, {\"root\": \"abaya\", \"meaning\": \"shoulder\"},\n",
    "    {\"root\": \"daya\", \"meaning\": \"blood\"}, {\"root\": \"olo\", \"meaning\": \"head\"},\n",
    "    {\"root\": \"leey\", \"meaning\": \"neck\"}, {\"root\": \"sabot\", \"meaning\": \"hair\"},\n",
    "    {\"root\": \"arong\", \"meaning\": \"nose\"}, {\"root\": \"angot\", \"meaning\": \"to sniff/smell\"},\n",
    "    {\"root\": \"bebey\", \"meaning\": \"mouth\"}, {\"root\": \"ngipin\", \"meaning\": \"tooth\"},\n",
    "    {\"root\": \"dila\", \"meaning\": \"tongue\"}, {\"root\": \"kalis\", \"meaning\": \"to laugh\"},\n",
    "    {\"root\": \"akis\", \"meaning\": \"to cry\"}, {\"root\": \"soka\", \"meaning\": \"to vomit\"},\n",
    "    {\"root\": \"kan\", \"meaning\": \"to eat\"}, {\"root\": \"inom\", \"meaning\": \"to drink\"},\n",
    "    {\"root\": \"kayat\", \"meaning\": \"to bite\"}, {\"root\": \"sepsep\", \"meaning\": \"to suck\"},\n",
    "    {\"root\": \"toly\", \"meaning\": \"ear\"}, {\"root\": \"ingar\", \"meaning\": \"to hear\"},\n",
    "    {\"root\": \"mata\", \"meaning\": \"eye\"}, {\"root\": \"kit\", \"meaning\": \"to see\"},\n",
    "    {\"root\": \"elek\", \"meaning\": \"to sleep\"}, {\"root\": \"taynep\", \"meaning\": \"to dream\"},\n",
    "    {\"root\": \"tekre\", \"meaning\": \"to sit\"}, {\"root\": \"ideng\", \"meaning\": \"to stand\"},\n",
    "    {\"root\": \"lalaki\", \"meaning\": \"man/male\"}, {\"root\": \"babayi\", \"meaning\": \"woman/female\"},\n",
    "    {\"root\": \"anak\", \"meaning\": \"child\"}, {\"root\": \"ahawa\", \"meaning\": \"spouse\"},\n",
    "    {\"root\": \"ina\", \"meaning\": \"mother\"}, {\"root\": \"tatay\", \"meaning\": \"father\"},\n",
    "    {\"root\": \"bali\", \"meaning\": \"house\"}, {\"root\": \"atep\", \"meaning\": \"roof\"},\n",
    "    {\"root\": \"ngaran\", \"meaning\": \"name\"}, {\"root\": \"robir\", \"meaning\": \"rope\"},\n",
    "    {\"root\": \"tayi\", \"meaning\": \"to sew\"}, {\"root\": \"kadayem\", \"meaning\": \"needle\"},\n",
    "    {\"root\": \"takaw\", \"meaning\": \"to steal\"}, {\"root\": \"pati\", \"meaning\": \"to kill\"},\n",
    "    {\"root\": \"tadem\", \"meaning\": \"sharp\"}, {\"root\": \"obra\", \"meaning\": \"to work\"},\n",
    "    {\"root\": \"tanem\", \"meaning\": \"to plant\"}, {\"root\": \"pili\", \"meaning\": \"to choose\"},\n",
    "    {\"root\": \"pespes\", \"meaning\": \"to squeeze\"}, {\"root\": \"kotkot\", \"meaning\": \"to dig\"},\n",
    "    {\"root\": \"haliw\", \"meaning\": \"to buy\"}, {\"root\": \"bantak\", \"meaning\": \"to throw\"},\n",
    "    {\"root\": \"aso\", \"meaning\": \"dog\"}, {\"root\": \"manok\", \"meaning\": \"bird/chicken\"},\n",
    "    {\"root\": \"salay\", \"meaning\": \"egg\"}, {\"root\": \"pakpak\", \"meaning\": \"wing\"},\n",
    "    {\"root\": \"lompad\", \"meaning\": \"to fly\"}, {\"root\": \"ikoy\", \"meaning\": \"tail\"},\n",
    "    {\"root\": \"olay\", \"meaning\": \"snake\"}, {\"root\": \"bolati\", \"meaning\": \"worm\"},\n",
    "    {\"root\": \"gigang\", \"meaning\": \"spider\"}, {\"root\": \"kona\", \"meaning\": \"fish\"},\n",
    "    {\"root\": \"yamot\", \"meaning\": \"root\"}, {\"root\": \"bonga\", \"meaning\": \"fruit\"},\n",
    "    {\"root\": \"bato\", \"meaning\": \"stone\"}, {\"root\": \"boyangin\", \"meaning\": \"sand\"},\n",
    "    {\"root\": \"ranom\", \"meaning\": \"water\"}, {\"root\": \"asin\", \"meaning\": \"salt\"},\n",
    "    {\"root\": \"langit\", \"meaning\": \"sky\"}, {\"root\": \"bulan\", \"meaning\": \"moon\"},\n",
    "    {\"root\": \"bitoen\", \"meaning\": \"star\"}, {\"root\": \"gonem\", \"meaning\": \"cloud\"},\n",
    "    {\"root\": \"rapeg\", \"meaning\": \"rain\"}, {\"root\": \"kodor\", \"meaning\": \"thunder\"},\n",
    "    {\"root\": \"kimat\", \"meaning\": \"lightning\"}, {\"root\": \"emot\", \"meaning\": \"warm\"},\n",
    "    {\"root\": \"rayep\", \"meaning\": \"cold\"}, {\"root\": \"albet\", \"meaning\": \"wet\"},\n",
    "    {\"root\": \"byat\", \"meaning\": \"heavy\"}\n",
    "]\n",
    "\n",
    "# Convert word list to DataFrame\n",
    "word_list_df = pd.DataFrame(root_word_list)\n",
    "unique_roots = word_list_df['root'].unique()\n",
    "\n",
    "# Generate all 3 possible assimilated forms for each root\n",
    "all_generated_forms = []\n",
    "\n",
    "for idx, row in word_list_df.iterrows():\n",
    "    root = row['root']\n",
    "    meaning = row['meaning']\n",
    "    \n",
    "    # Apply all 3 prefixes to each root\n",
    "    for prefix in [\"mang\", \"nang\", \"pang\"]:\n",
    "        assimilated_form = apply_assimilation_reduction(prefix, root)\n",
    "        \n",
    "        # Check if this generated form exists in the original lexicon\n",
    "        exists_in_lexicon = assimilated_form in df['word'].values\n",
    "        \n",
    "        all_generated_forms.append({\n",
    "            'root_word': root,\n",
    "            'root_meaning': meaning,\n",
    "            'prefix_applied': prefix,\n",
    "            'generated_form': assimilated_form,\n",
    "            'exists_in_lexicon': exists_in_lexicon\n",
    "        })\n",
    "\n",
    "generated_df = pd.DataFrame(all_generated_forms)\n",
    "\n",
    "# Display statistics\n",
    "print(f\"Total unique roots: {len(unique_roots)}\")\n",
    "print(f\"Total generated forms: {len(generated_df)} (3 per root)\")\n",
    "print(f\"Forms that exist in lexicon: {generated_df['exists_in_lexicon'].sum()}\")\n",
    "print(f\"\\nFirst 30 generated forms:\")\n",
    "generated_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Verify Which Generated Forms Match Original Lexicon\n",
    "\n",
    "Check which of our generated forms actually appear in the original Bolinao lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roots that produce 1 valid form: 7\n",
      "Roots that produce 2 valid forms: 1\n",
      "Roots that produce 3 valid forms: 0\n",
      "\n",
      "Existing forms in lexicon:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_word</th>\n",
       "      <th>root_meaning</th>\n",
       "      <th>prefix_applied</th>\n",
       "      <th>generated_form</th>\n",
       "      <th>exists_in_lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>sepsep</td>\n",
       "      <td>to suck</td>\n",
       "      <td>pang</td>\n",
       "      <td>panepsep</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>ingar</td>\n",
       "      <td>to hear</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangingar</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>anak</td>\n",
       "      <td>child</td>\n",
       "      <td>mang</td>\n",
       "      <td>manganak</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>anak</td>\n",
       "      <td>child</td>\n",
       "      <td>pang</td>\n",
       "      <td>panganak</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>bali</td>\n",
       "      <td>house</td>\n",
       "      <td>mang</td>\n",
       "      <td>mamali</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>ngaran</td>\n",
       "      <td>name</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangngaran</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tanem</td>\n",
       "      <td>to plant</td>\n",
       "      <td>pang</td>\n",
       "      <td>pananem</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>aso</td>\n",
       "      <td>dog</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangaso</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>salay</td>\n",
       "      <td>egg</td>\n",
       "      <td>mang</td>\n",
       "      <td>manalay</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    root_word root_meaning prefix_applied generated_form  exists_in_lexicon\n",
       "89     sepsep      to suck           pang       panepsep               True\n",
       "93      ingar      to hear           mang      mangingar               True\n",
       "120      anak        child           mang       manganak               True\n",
       "122      anak        child           pang       panganak               True\n",
       "132      bali        house           mang         mamali               True\n",
       "140    ngaran         name           pang     pangngaran               True\n",
       "164     tanem     to plant           pang        pananem               True\n",
       "180       aso          dog           mang        mangaso               True\n",
       "186     salay          egg           mang        manalay               True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to show only forms that exist in lexicon\n",
    "existing_forms = generated_df[generated_df['exists_in_lexicon'] == True].copy()\n",
    "\n",
    "# Group by root to see how many valid forms each root produces\n",
    "forms_per_root = existing_forms.groupby('root_word').size()\n",
    "\n",
    "print(f\"Roots that produce 1 valid form: {(forms_per_root == 1).sum()}\")\n",
    "print(f\"Roots that produce 2 valid forms: {(forms_per_root == 2).sum()}\")\n",
    "print(f\"Roots that produce 3 valid forms: {(forms_per_root == 3).sum()}\")\n",
    "print(f\"\\nExisting forms in lexicon:\")\n",
    "existing_forms.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. View Forms NOT in Lexicon (Potential New Words)\n",
    "\n",
    "These are grammatically valid forms we can generate, but they don't appear in the current lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total generated forms NOT in lexicon: 252\n",
      "\n",
      "These are grammatically valid but not documented:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total generated forms NOT in lexicon: 252\n",
      "\n",
      "These are grammatically valid but not documented:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_word</th>\n",
       "      <th>root_meaning</th>\n",
       "      <th>prefix_applied</th>\n",
       "      <th>generated_form</th>\n",
       "      <th>exists_in_lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gamet</td>\n",
       "      <td>hand</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangamet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gamet</td>\n",
       "      <td>hand</td>\n",
       "      <td>nang</td>\n",
       "      <td>nangamet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gamet</td>\n",
       "      <td>hand</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangamet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wiri</td>\n",
       "      <td>left</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangwiri</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wiri</td>\n",
       "      <td>left</td>\n",
       "      <td>nang</td>\n",
       "      <td>nangwiri</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wiri</td>\n",
       "      <td>left</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangwiri</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wanan</td>\n",
       "      <td>right</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangwanan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wanan</td>\n",
       "      <td>right</td>\n",
       "      <td>nang</td>\n",
       "      <td>nangwanan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wanan</td>\n",
       "      <td>right</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangwanan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bitih</td>\n",
       "      <td>leg/foot</td>\n",
       "      <td>mang</td>\n",
       "      <td>mamitih</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bitih</td>\n",
       "      <td>leg/foot</td>\n",
       "      <td>nang</td>\n",
       "      <td>namitih</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bitih</td>\n",
       "      <td>leg/foot</td>\n",
       "      <td>pang</td>\n",
       "      <td>pamitih</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>daan</td>\n",
       "      <td>road/path</td>\n",
       "      <td>mang</td>\n",
       "      <td>manaan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>daan</td>\n",
       "      <td>road/path</td>\n",
       "      <td>nang</td>\n",
       "      <td>nanaan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>daan</td>\n",
       "      <td>road/path</td>\n",
       "      <td>pang</td>\n",
       "      <td>panaan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tangoy</td>\n",
       "      <td>to swim</td>\n",
       "      <td>mang</td>\n",
       "      <td>manangoy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tangoy</td>\n",
       "      <td>to swim</td>\n",
       "      <td>nang</td>\n",
       "      <td>nanangoy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tangoy</td>\n",
       "      <td>to swim</td>\n",
       "      <td>pang</td>\n",
       "      <td>panangoy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tapok</td>\n",
       "      <td>dust</td>\n",
       "      <td>mang</td>\n",
       "      <td>manapok</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tapok</td>\n",
       "      <td>dust</td>\n",
       "      <td>nang</td>\n",
       "      <td>nanapok</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tapok</td>\n",
       "      <td>dust</td>\n",
       "      <td>pang</td>\n",
       "      <td>panapok</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>katat</td>\n",
       "      <td>skin</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangatat</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>katat</td>\n",
       "      <td>skin</td>\n",
       "      <td>nang</td>\n",
       "      <td>nangatat</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>katat</td>\n",
       "      <td>skin</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangatat</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gorot</td>\n",
       "      <td>back</td>\n",
       "      <td>mang</td>\n",
       "      <td>mangorot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gorot</td>\n",
       "      <td>back</td>\n",
       "      <td>nang</td>\n",
       "      <td>nangorot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gorot</td>\n",
       "      <td>back</td>\n",
       "      <td>pang</td>\n",
       "      <td>pangorot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tyan</td>\n",
       "      <td>belly</td>\n",
       "      <td>mang</td>\n",
       "      <td>manyan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tyan</td>\n",
       "      <td>belly</td>\n",
       "      <td>nang</td>\n",
       "      <td>nanyan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tyan</td>\n",
       "      <td>belly</td>\n",
       "      <td>pang</td>\n",
       "      <td>panyan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   root_word root_meaning prefix_applied generated_form  exists_in_lexicon\n",
       "0      gamet         hand           mang       mangamet              False\n",
       "1      gamet         hand           nang       nangamet              False\n",
       "2      gamet         hand           pang       pangamet              False\n",
       "3       wiri         left           mang       mangwiri              False\n",
       "4       wiri         left           nang       nangwiri              False\n",
       "5       wiri         left           pang       pangwiri              False\n",
       "6      wanan        right           mang      mangwanan              False\n",
       "7      wanan        right           nang      nangwanan              False\n",
       "8      wanan        right           pang      pangwanan              False\n",
       "9      bitih     leg/foot           mang        mamitih              False\n",
       "10     bitih     leg/foot           nang        namitih              False\n",
       "11     bitih     leg/foot           pang        pamitih              False\n",
       "12      daan    road/path           mang         manaan              False\n",
       "13      daan    road/path           nang         nanaan              False\n",
       "14      daan    road/path           pang         panaan              False\n",
       "15    tangoy      to swim           mang       manangoy              False\n",
       "16    tangoy      to swim           nang       nanangoy              False\n",
       "17    tangoy      to swim           pang       panangoy              False\n",
       "18     tapok         dust           mang        manapok              False\n",
       "19     tapok         dust           nang        nanapok              False\n",
       "20     tapok         dust           pang        panapok              False\n",
       "21     katat         skin           mang       mangatat              False\n",
       "22     katat         skin           nang       nangatat              False\n",
       "23     katat         skin           pang       pangatat              False\n",
       "24     gorot         back           mang       mangorot              False\n",
       "25     gorot         back           nang       nangorot              False\n",
       "26     gorot         back           pang       pangorot              False\n",
       "27      tyan        belly           mang         manyan              False\n",
       "28      tyan        belly           nang         nanyan              False\n",
       "29      tyan        belly           pang         panyan              False"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show forms that DON'T exist in lexicon (potential new words)\n",
    "non_existing_forms = generated_df[generated_df['exists_in_lexicon'] == False]\n",
    "\n",
    "print(f\"Total generated forms NOT in lexicon: {len(non_existing_forms)}\")\n",
    "print(f\"\\nThese are grammatically valid but not documented:\")\n",
    "non_existing_forms.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Generated Forms\n",
    "\n",
    "Save all generated forms (both existing and potential new words) to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All generated forms saved to 'bolinao_all_generated_assimilated_forms.csv'\n",
      "Existing forms saved to 'bolinao_generated_forms_in_lexicon.csv'\n",
      "Potential new words saved to 'bolinao_potential_new_words.csv'\n"
     ]
    }
   ],
   "source": [
    "# Export all generated forms\n",
    "generated_df.to_csv(\"bolinao_all_generated_assimilated_forms.csv\", index=False)\n",
    "print(\"All generated forms saved to 'bolinao_all_generated_assimilated_forms.csv'\")\n",
    "\n",
    "# Export only existing forms\n",
    "existing_forms.to_csv(\"bolinao_generated_forms_in_lexicon.csv\", index=False)\n",
    "print(\"Existing forms saved to 'bolinao_generated_forms_in_lexicon.csv'\")\n",
    "\n",
    "# Export potential new words\n",
    "non_existing_forms.to_csv(\"bolinao_potential_new_words.csv\", index=False)\n",
    "print(\"Potential new words saved to 'bolinao_potential_new_words.csv'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
